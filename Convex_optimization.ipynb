{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convex optimization: from simplest and intuitive methods to complicated and advanced tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note\n",
    "\n",
    "This project is based on my course paperwork 'Gradient descent algorithm and its modifications: from theory to practice and applications'. It is a practical survey made in Latex. The idea was to provide intuitive, mathematical and programming explanation of tools used for minimizing convex loss functions. Here I want to provide a summary of that work in Jupyter Notebook format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Consider the simplest case\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Suppose we have an independent vector and a dependent one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3 5 7 9]\n",
      "[ 12  28  52  84 124]\n"
     ]
    }
   ],
   "source": [
    "# choose arbitrary vectors\n",
    "import numpy as np\n",
    "x = np.array([1,3,5,7,9])\n",
    "y = np.array(x**2 + 4 * x + 7)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have written the function $y(x)$. However, suppose we do not know it explicitly. \n",
    "By taking a closer look we can see that the dependence is either linear or quadatric.\n",
    "Cubic case is not very likely to be the one since $7^3=343>>84$; $9^3=729>>124$.\n",
    "It still might be due to constants but we will not consider it.\n",
    "We will now compare the performance of linear and quadratic cases by looking at the Euclidian norms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Linear case\n",
    "\n",
    "###### In this classical case we approximate y as a linear combination of x:\n",
    "\n",
    "### $\\hat{y} = ax + b$, \n",
    "\n",
    "where $\\hat{y}$ is predicted value of y; a and b are parameters on which it depends on\n",
    "\n",
    "###### Now we can find these parameters using scipy optimization methods (probably the simplest way to do this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 14., -10.])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "def func(x, a, b):\n",
    "    return a * x + b\n",
    "popt, pcov = curve_fit(func, x, y, p0=(1,1)) #we need to put initial guesses, let a = b = 1\n",
    "popt # coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we approximate function linearly, scipy tells us we get\n",
    "\n",
    "### $\\hat{y} = 14x - 10$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Quadratic case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is indeed the right case in the problem since I have created it by myself. Here\n",
    "\n",
    "### $\\hat{y} = ax^2 + bx + c$. \n",
    "\n",
    "It is time to find those parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 4., 7.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def func(x, a, b, c):\n",
    "    return a * x ** 2 + b * x + c\n",
    "popt, pcov = curve_fit(func, x, y, p0=(1,1,1)) \n",
    "popt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we put those coefficients to the function, we get that\n",
    "\n",
    "### $\\hat{y} = x^2 + 4x + 7$\n",
    "\n",
    "We got the initial function and this proves the method works.\n",
    "\n",
    "Nevertheless, it is still a good idea to compare the methods because usually the function is not known"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Possible way of comparing methods - Euclidian norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do so we will define a cost function which we usually want to minimize\n",
    "\n",
    "###### The approximation, resulting in lower loss, is better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $cost = \\sum_{i=1}^n (y - \\hat{y})^2$\n",
    "\n",
    "n - number of observations, here we have 5. Usually with deal with another versions of cost function, but here this one will work just fine\n",
    "\n",
    "We see that it is exactly the Euclidian norm squared\n",
    "\n",
    "So the function with lower Euclidian norm is better (we know that quadratic norm should be 0 since we just substract a function from itself but I want just to show that)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of linear norm is 14.966629547095765, The value of quadratic norm is 0.0\n",
      "As we see, quadratic approximation is better\n"
     ]
    }
   ],
   "source": [
    "linear_norm = np.linalg.norm(y - np.array(14 * x - 10))\n",
    "quadratic_norm = np.linalg.norm(y - np.array(x ** 2 + 4 * x + 7))\n",
    "print(f'The value of linear norm is {linear_norm}, The value of quadratic norm is {quadratic_norm}')\n",
    "if linear_norm <= quadratic_norm:\n",
    "    print('As we see, linear approximation is better')\n",
    "else:\n",
    "    print('As we see, quadratic approximation is better')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Introduction to Gradient Descent methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Swich to iterative methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is time to introduce the Gradient Descent algorithm (I will sometimes denote it as GD or BGD). To do so, we will define another cost functions for both linear and quadratic cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Start with linear case\n",
    "\n",
    "### $cost_{linear} = \\frac{1}{2n}\\sum_{i=1}^n (b + ax - y)^2$\n",
    "\n",
    "For solving the problem, we will code the simplest possible Gradient Descent algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " current value of a is 20.6, current value of b is 3.0, iteration 0, cost is 5212.8\n",
      " current value of a is 13.014378868447867, current value of b is -3.541607776734829, iteration 50, cost is 55.15732745561401\n",
      " current value of a is 13.456857494803327, current value of b is -6.440998487785213, iteration 100, cost is 47.94525035744757\n",
      " current value of a is 13.700692535626, current value of b is -8.038754639652971, iteration 150, cost is 45.75513054438215\n",
      " current value of a is 13.835061779601366, current value of b is -8.919224015420816, iteration 200, cost is 45.090048248353725\n",
      " current value of a is 13.909108125301298, current value of b is -9.404420909051161, iteration 250, cost is 44.888080092159036\n",
      " current value of a is 13.94991256201093, current value of b is -9.671796506735337, iteration 300, cost is 44.82674762795081\n",
      " current value of a is 13.972398506988378, current value of b is -9.819138155405156, iteration 350, cost is 44.8081225573618\n",
      " current value of a is 13.984789750742756, current value of b is -9.900333154577755, iteration 400, cost is 44.802466608935106\n",
      " current value of a is 13.991618146077458, current value of b is -9.945076972433437, iteration 450, cost is 44.80074904483501\n",
      " current value of a is 13.995381043795494, current value of b is -9.9697337771222, iteration 500, cost is 44.80022746539056\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(13.995381043795494, -9.9697337771222)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gradient_descent(x,y):\n",
    "    b = a = 0\n",
    "    iterations = 501\n",
    "    learning_rate = 0.05\n",
    "    n = len(x)\n",
    "    for i in range(iterations):\n",
    "        y_predicted = a * x + b\n",
    "        cost = (1/n) * sum([val**2 for val in (y-y_predicted)])\n",
    "        ad = -(1/n)*sum(x*(y-y_predicted))\n",
    "        bd = -(1/n)*sum(y-y_predicted)\n",
    "        a = a - learning_rate * ad\n",
    "        b = b - learning_rate * bd\n",
    "        if i%50 == 0:\n",
    "            print(f' current value of a is {a}, current value of b is {b}, iteration {i}, cost is {cost}')\n",
    "    return a, b\n",
    "gradient_descent(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Within 500 iterations we got to values which are very close to [14, -10], which are optimum values due to results we got before\n",
    "\n",
    "We need to take into account that this algorithm is the simplest and does not perform well\n",
    "\n",
    "we still converge and get wanted result but do it slowly and with some risk of skipping the optimum point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Quadratic case\n",
    "\n",
    "### $cost_{quadratic} = \\frac{1}{2n}\\sum_{i=1}^n (ax^2 + bx + c - y)^2$\n",
    "\n",
    "Here I want to write a more complex and sophisticated code to improve the algorithm.\n",
    "\n",
    "###### So there are several additions & improvements:\n",
    "\n",
    "###### 1) Now the function of the algorithm depends on more parameters:\n",
    "\n",
    "(start - initial guesses, learn_rate - learning rate, n_iter - number of iterstions, tolerance - minimal changes by iteration (this allows us not to make iterstions that are not actually needed due to their uselessness)); now we can easily control some things about the algorithm without changing the code\n",
    "\n",
    "###### 2) There was defined a new_function which returns the gradient of our function\n",
    "\n",
    "After that we can implement it in the algorithm. As a result it is required to write less rows of code and it looks more generalised as it is always less tedious to change the gradient instead of half of the code\n",
    "\n",
    "###### 3) Some other small changes mostly related to 1) and 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector is [0.89966666 5.14609987 4.37036782], iteration 5000\n",
      "vector is [0.93300072 4.76531152 5.24413714], iteration 10000\n",
      "vector is [0.95526278 4.51101906 5.82756321], iteration 15000\n",
      "vector is [0.97012776 4.34122115 6.21713247], iteration 20000\n",
      "vector is [0.9800535  4.22784252 6.47725833], iteration 25000\n",
      "vector is [0.98668119 4.15213657 6.65095135], iteration 30000\n",
      "vector is [0.99110667 4.10158568 6.76693084], iteration 35000\n",
      "vector is [0.99406169 4.06783148 6.84437346], iteration 40000\n",
      "vector is [0.99603483 4.0452929  6.89608398], iteration 45000\n",
      "vector is [0.99735235 4.03024329 6.93061248], iteration 50000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.99735235, 4.03024329, 6.93061248])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gradient_descent(gradient, x, y, start, learn_rate, n_iter, tolerance=1e-06,\n",
    "    dtype=\"float64\"\n",
    "):\n",
    "    dtype_ = np.dtype(dtype)\n",
    "    x, y = np.array(x, dtype=dtype_), np.array(y, dtype=dtype_)\n",
    "    vector = np.array(start, dtype=dtype_)\n",
    "    learn_rate = np.array(learn_rate, dtype=dtype_)\n",
    "    n_iter = int(n_iter)\n",
    "    tolerance = np.array(tolerance, dtype=dtype_)\n",
    "    iteration_counter = 0\n",
    "    iteration_5thousand = 0\n",
    "    # Performing the gradient descent loop\n",
    "    for _ in range(n_iter):\n",
    "        # Recalculating the difference\n",
    "        diff = -learn_rate * np.array(gradient(x, y, vector), dtype_)\n",
    "        # Checking if the absolute difference is small enough\n",
    "        if np.all(np.abs(diff) <= tolerance):\n",
    "            break\n",
    "        # Updating the values of the variables\n",
    "        vector += diff\n",
    "        if iteration_counter == 5000:\n",
    "            iteration_5thousand += 5000\n",
    "            iteration_counter = 0\n",
    "            print(f'vector is {vector}, iteration {iteration_5thousand}')\n",
    "        iteration_counter += 1\n",
    "    return vector if vector.shape else vector.item()\n",
    "# define a function which returns our gradient\n",
    "def returned_gradient(x, y, b): \n",
    "    res = b[0] * x ** 2 + b[1] * x + b[2] - y\n",
    "    return (res * x ** 2).mean(), (res * x).mean(), res.mean()\n",
    "gradient_descent(returned_gradient, x, y, start=[1,1,1],\n",
    "learn_rate=0.001011, n_iter=50001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### We see that within 50 000 iterations for a given learning rate we end up with following vector of values (rounded to two decimal places):\n",
    "\n",
    "[1, 4.03, 6.93] which is very close to the optimal one [1, 4, 7]. Of course if we ran more iterations we would reach ever closer point to the optimum but it will be too long"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Interpretation of intermediate results \n",
    "\n",
    "So, the algorithm works but there is a problem with the learning rate. If we choose it too big, we diverge (for example, if we set it to be 0.01 in the latter example); if we set it to be too small, we fail to converge (or it will take too many iterations). There are many ways to deal with this problem and actually this is what I am going to talk about in the nearest future"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Some more things before we move to the SGD algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear case we took a look at has a property that we can find the optimal solution explicitly by using Pseudo-inverse matrices (linear regression problem). Let's have a look at the most popular example with house price prediction\n",
    "\n",
    "I will create observations on my own in order not to read csv or excel files with pandas and not to send you additional files except this jupiter notebook\n",
    "\n",
    "Here, as usually, we have $\\hat{y}$ which is the price we are trying to predict. It depends on several parameters: square feet, number of rooms, age and city and the function is linearly dependent on each of those parameters\n",
    "\n",
    "### $\\hat{y} = \\sum_{i=1}^n \\theta_i x_i$, where $x_1 = 1$ since $\\theta_1$ is the intercept\n",
    "\n",
    "###### We will solve a problem using two approaches:\n",
    "\n",
    "1) Sklearn built-in linear regression function\n",
    "\n",
    "2) Pseudo-inverse matrices\n",
    "\n",
    "This two things are actually the same but in first case we will do it automatically, and in the second we calculate the matrix multiplication by hands. And in both cases we deal with categorical variables. Matrices do not understand what do we mean by 'Moscow' or 'Odintsovo', they need numbers. Suppose we say that 1 - 'Moscow', 2 - 'Saint Petersburg', 3 - 'Odintsovo'. It will result in mistakes because Python will think that 'Moscow' < 'Odintsovo' or that 'Moscow' and 'Saint Petersburg' add up to 'Odintsovo'. To deal with the problem we will use special types of variables - dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    square feet  number of rooms   age  Moscow  Saint Petersburg\n",
      "0          35.0              1.0   1.0       1                 0\n",
      "1          45.0              1.0   3.0       1                 0\n",
      "2          60.0              2.0   4.0       1                 0\n",
      "3          75.0              3.0   8.0       1                 0\n",
      "4          96.0              4.0  15.0       1                 0\n",
      "5          43.0              1.0   2.0       0                 1\n",
      "6          58.0              2.0   6.0       0                 1\n",
      "7          76.0              3.0   8.0       0                 1\n",
      "8          37.0              1.0   1.0       0                 1\n",
      "9         100.0              4.0  15.0       0                 1\n",
      "10         41.0              1.0  16.0       0                 0\n",
      "11        150.0              7.0   1.0       0                 0\n",
      "12         29.0              1.0   2.0       0                 0\n",
      "13         75.0              3.0  15.0       0                 0\n",
      "14         43.0              1.0   2.0       0                 0\n",
      "the intercept of the model is 2.1 and the coefficients are [0.13 0.84 0.02 5.8  1.9 ]\n"
     ]
    }
   ],
   "source": [
    "# first approach\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "square_feet = np.array([35,45,60,75,96,43,58,76,37,100,41,150,29,75,43])\n",
    "number_of_rooms = np.array([1,1,2,3,4,1,2,3,1,4,1,7,1,3,1])\n",
    "age = np.array([1,3,4,8,15,2,6,8,1,15,16,1,2,15,2])\n",
    "#I put numbers, because I do not want tohave problems with matrices, in DataFrame I will substitute them for cities\n",
    "city = np.array([1,1,1,1,1,2,2,2,2,2,3,3,3,3,3]) # 1 - 'Moscow', 2 - 'Saint Petersburg', 3 - 'Odintsovo'\n",
    "first_price = np.array([11,12,15,18,22,12,14.5,18,11,23,10.5,34,9,17,12])\n",
    "final_price = []\n",
    "for i in range(len(first_price)):\n",
    "    if city[i] == 1:\n",
    "        final_price.append(first_price[i] * 1.15)\n",
    "    elif city[i] == 2:\n",
    "        final_price.append(first_price[i] * 0.9)\n",
    "    elif city[i] == 3:\n",
    "        final_price.append(first_price[i] * 0.8)\n",
    "final_price = np.array(final_price)\n",
    "independent_features = np.zeros(shape = [4,15])\n",
    "independent_features[0] = square_feet\n",
    "independent_features[1] = number_of_rooms\n",
    "independent_features[2] = age\n",
    "independent_features[3] = city\n",
    "independent_features = independent_features.T\n",
    "df2 = pd.DataFrame(independent_features, columns = ['square feet', 'number of rooms', 'age', 'town'])\n",
    "df2.loc[df2['town'] == 1, 'town'] = 'Moscow'\n",
    "df2.loc[df2['town'] == 2, 'town'] = 'Saint Petersburg'\n",
    "df2.loc[df2['town'] == 3, 'town'] = 'Odintsovo'\n",
    "dummies = pd.get_dummies(df2.town)\n",
    "merged = pd.concat([df2.drop(['town'], axis = 1), dummies], axis = 1)\n",
    "# If we use One Hot Encoding, we always need to drop one dummy column\n",
    "merged = merged.drop(['Odintsovo'], axis =1 )\n",
    "print(merged)\n",
    "model = LinearRegression()\n",
    "X = merged\n",
    "y = final_price\n",
    "model.fit(X, y)\n",
    "print(f'the intercept of the model is {round(model.intercept_,2)} and the coefficients are {np.round(model.coef_,2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.  35.   1.   1.   1.   0.]\n",
      " [  1.  45.   1.   3.   1.   0.]\n",
      " [  1.  60.   2.   4.   1.   0.]\n",
      " [  1.  75.   3.   8.   1.   0.]\n",
      " [  1.  96.   4.  15.   1.   0.]\n",
      " [  1.  43.   1.   2.   0.   1.]\n",
      " [  1.  58.   2.   6.   0.   1.]\n",
      " [  1.  76.   3.   8.   0.   1.]\n",
      " [  1.  37.   1.   1.   0.   1.]\n",
      " [  1. 100.   4.  15.   0.   1.]\n",
      " [  1.  41.   1.  16.   0.   0.]\n",
      " [  1. 150.   7.   1.   0.   0.]\n",
      " [  1.  29.   1.   2.   0.   0.]\n",
      " [  1.  75.   3.  15.   0.   0.]\n",
      " [  1.  43.   1.   2.   0.   0.]]\n",
      "the intercept of the model is 2.1 and the coefficients are [0.13 0.84 0.02 5.8  1.9 ]\n"
     ]
    }
   ],
   "source": [
    "# second approach\n",
    "merged1 = np.array(merged)\n",
    "X = merged1\n",
    "# remember that x_1 = 1\n",
    "x0 = np.ones((15,1))\n",
    "X = np.hstack((x0, X))\n",
    "print(X)\n",
    "# calculate Pseudo-inverse and multiply it by y\n",
    "coefficient = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)\n",
    "coefficient\n",
    "print(f'the intercept of the model is {round(coefficient[0],2)} and the coefficients are {np.round(coefficient[1:],2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result, \n",
    "\n",
    "### $\\hat{y} = 2.1 + 0.13x_2 + 0.84x_3 + 0.02x_4 + 5.8x_5 + 1.9x_6$\n",
    "\n",
    "where $x_2, x_3, x_4$ - integer variables standing for square_feet, rooms, age;\n",
    "\n",
    "$x_5, x_6$ - binary variables representing the city ($x_5$ - 'Moscow', $x_6$ - 'Saint Petersburg'). The value is 1 if the city the house is at suits the name of the variable, 0 if it is in another city. $x_5 = x_6 = 0$ means it is 'Odintsovo'. The interpretation of the results will take long time. However, if we take a closer look at what we got, we see that it makes sense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Advanced iterative methods for solving convex optimization problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 When Stochastic gradient descent (SGD) is needed (switch from GD to SGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have a dataset of n observations, $f_i(x)$ - loss function with respect to the observation of index i, x - vector of parameters. By summing those functions, we get a total loss function\n",
    "\n",
    "### $f(x) = \\frac{1}{n} \\sum_ {i=1} ^ n f_i(x)$\n",
    "\n",
    "Now we can compute the gradient:\n",
    "\n",
    "### $\\nabla f(x) = \\frac{1}{n} \\sum_ {i=1} ^ n \\nabla f_i(x)$\n",
    "\n",
    "What we do then is uptade the vector x at each iteration using this method:\n",
    "\n",
    "### $x^{(t+1)} = x^{(t)} - \\eta \\nabla f(x)$\n",
    "\n",
    "Now let's consider a general example. We have n observations, m parameters the function depends on and T iterations of the GD algorithm. In that case we will have to calculate n * m * T terms. Choice of T depends on us, but if n and m are huge, algorithm will take much time and will be slow. The comptutational cost depends for each variable linearly grows with n. There is a way to make it constant and make algorithm n times faster. This is where we speak about SGD. At each iteration we randomly choose just 1 observation and calculate derivatives without taking into consideration all other observations.\n",
    "\n",
    "The new introduced algorithm will also converge. The main idea is that gradient of the particular observation $\\nabla f_i(x)$ is an unbiased estimate of the gradient $\\nabla f(x)$ because\n",
    "\n",
    "### $\\mathbb{E}_i \\nabla f_i(x) = \\frac{1}{n} \\sum_ {i=1} ^ n \\nabla f_i(x) = \\nabla f(x)$\n",
    "\n",
    "So, it is efficient to use it. The new algorithm will be:\n",
    "\n",
    "### $x^{(t+1)} = x^{(t)} - \\eta \\nabla f_i(x^{(t)})$\n",
    "\n",
    "And now we are ready to code it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector is [0.94601733 4.60191576 5.56858407], iteration 5000\n",
      "vector is [0.97668389 4.21306684 6.49454394], iteration 10000\n",
      "vector is [0.99199708 4.07629051 6.81764439], iteration 15000\n",
      "vector is [0.99854278 4.02722549 6.93461682], iteration 20000\n",
      "vector is [0.99922692 4.00976972 6.97614736], iteration 25000\n",
      "vector is [0.99961731 4.00374372 6.99112666], iteration 30000\n",
      "vector is [0.99989904 4.00149366 6.99635631], iteration 35000\n",
      "vector is [0.99992526 4.00108509 6.99707505], iteration 40000\n",
      "vector is [0.99993979 4.00095661 6.99725167], iteration 45000\n",
      "vector is [0.99992229 4.00090532 6.99742005], iteration 50000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.99992229, 4.00090532, 6.99742005])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sgd(\n",
    "    gradient, x, y, start, learn_rate=0.1, batch_size=1, n_iter=50,\n",
    "    tolerance=1e-06, dtype=\"float64\", random_state=None\n",
    "):\n",
    "    # Setting up the data type for NumPy arrays\n",
    "    dtype_ = np.dtype(dtype)\n",
    "    x, y = np.array(x, dtype=dtype_), np.array(y, dtype=dtype_)\n",
    "    n_obs = x.shape[0] #number of elements in the vector in case of 1d and number of rows in case of 2d\n",
    "    xy = np.c_[x.reshape(n_obs, -1), y.reshape(n_obs, 1)]\n",
    "    # .reshape() to make sure that both x and y become two-dimensional arrays \n",
    "    # with n_obs rows and that y has exactly one column\n",
    "    # numpy.c_[] conveniently concatenates the columns of x and y into a single array, xy. \n",
    "    #This is one way to make data suitable for random selection.\n",
    "    \n",
    "    # Initializing the random number generator\n",
    "    seed = None if random_state is None else int(random_state)\n",
    "    rng = np.random.default_rng(seed=seed) #since we do not use random state, different numbers all the time\n",
    "    vector = np.array(start, dtype=dtype_)\n",
    "    learn_rate = np.array(learn_rate, dtype=dtype_)\n",
    "    batch_size = int(batch_size)\n",
    "    n_iter = int(n_iter)\n",
    "    tolerance = np.array(tolerance, dtype=dtype_)\n",
    "    iteration_counter = 0\n",
    "    iteration_5thousand = 0\n",
    "    for _ in range(n_iter):\n",
    "        rng.shuffle(xy) # a way to choose minibatches randomly\n",
    "        for start in range(0, n_obs, batch_size):\n",
    "            stop = start + batch_size\n",
    "            x_batch, y_batch = xy[start:stop, :-1], xy[start:stop, -1:]\n",
    "            grad = np.array(gradient(x_batch, y_batch, vector), dtype_)\n",
    "            diff = -learn_rate * grad\n",
    "            if np.all(np.abs(diff) <= tolerance):\n",
    "                break\n",
    "            vector += diff\n",
    "        if iteration_counter == 5000:\n",
    "            iteration_5thousand += 5000\n",
    "            iteration_counter = 0\n",
    "            print(f'vector is {vector}, iteration {iteration_5thousand}')\n",
    "        iteration_counter += 1\n",
    "    return vector if vector.shape else vector.item()\n",
    "# Apply to the previous quadratic result\n",
    "x = np.array([1,3,5,7,9])\n",
    "y = np.array(x**2 + 4 * x + 7)\n",
    "def returned_gradient(x, y, b): \n",
    "    res = b[0] * x ** 2 + b[1] * x + b[2] - y\n",
    "    return (res * x ** 2).mean(), (res * x).mean(), res.mean()\n",
    "sgd(returned_gradient, x, y, start=[1,1,1],\n",
    "learn_rate=0.0005, n_iter=50001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Some interesting changes in terms of code (in comparison with the previuos algorithm):\n",
    "\n",
    "###### 1) Function depends on presence or absence of random state\n",
    "This state allows us to choose the same samples all the time but we do not now need it, therefore, do not use\n",
    "\n",
    "###### 2) Batch_size is the number of observations we choose to perform an iteration\n",
    "Actually, SGD is a particular case of mini batch gradient descent algorithm. By definition of it, we choose a subset of the set of observations to save time. So, SGD is just the most extreme case of this where the size of subset is just one random sample point.\n",
    "\n",
    "###### 3) Everything is done randomly (in terms of choosing samples)\n",
    "This minimizes risks of errors and inconveniences. There was introduced one way to do this by making a merged vector xy\n",
    "\n",
    "Now we can compare the effectiveness of this algorithm with batch gradient descent. The results of the latter algorithm within the same number of iterations and the given learning rate which is now smaller are better than they were before since we got [1, 4, 7] which are indeed optimal values and previously we were just very close to them. Morevoer, SGD algorithm is 5 times faster (not exactly but very close to since we still need some comptutational cost to choose this random samples throughout iterations) since the number of observations is 5. That is why, it is definetely worth using. Note that depending on the situation, the SGD algorithm due to specificity of particular functions and randomness can require either less or bigger number of iterations to converge. In this particular example 50 000 iterations of the GD cost approximately as much as 250 000 iterations of SGD. That is why, if SGD will perform better within 250 000 iterations than SG within 50 000, we should use it. In examples I saw, SGD was always the best case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Can we do even better?\n",
    "\n",
    "Definitely, yes. Since GD and SGD are very sophisticated and well-studied algorithms, there are many possible modifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Stochastic gradient descent with momentum\n",
    "\n",
    "By introducing an additional term we will be able to remember what happened in the previous iterations and make algorithm faster. Now the formula is updated\n",
    "\n",
    "### $x_{i+1} = x_i - \\eta \\nabla f_i (x_i) + \\alpha \\Delta x_i$\n",
    "\n",
    "### $\\Delta x_i = x_i - x_{i-1} = \\alpha \\Delta x_{i-1} - \\eta \\nabla f_i(x_{i-1})$\n",
    "\n",
    "So, we move not exactly in the direction of gradient, we also pay attention to what happened to gradient in the past. The parameter $0 \\leq \\alpha \\leq 1$ is called decay rate and it represents the importance of previous moves. Now it is time to implement this in the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector is [1.08102775 5.16833988 5.35991633], iteration 5000\n",
      "vector is [0.94333543 4.44138849 6.07255598], iteration 10000\n",
      "vector is [1.10878676 4.21714837 6.6557175 ], iteration 15000\n",
      "vector is [0.99481088 4.05938771 6.87905713], iteration 20000\n",
      "vector is [0.99892059 4.02350591 6.92164191], iteration 25000\n",
      "vector is [1.00080183 4.0092069  6.97882448], iteration 30000\n",
      "vector is [0.99938713 4.01295522 6.9804388 ], iteration 35000\n",
      "vector is [0.99985415 4.00286301 6.99439914], iteration 40000\n",
      "vector is [1.00006926 3.99989567 6.99848159], iteration 45000\n",
      "vector is [0.99994639 4.00064369 6.99880139], iteration 50000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.99994639, 4.00064369, 6.99880139])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sgd_d(\n",
    "    gradient, x, y, start, learn_rate=0.1, decay_rate=0.3, batch_size=1,\n",
    "    n_iter=50, tolerance=1e-06, dtype=\"float64\", random_state=None\n",
    "):\n",
    "    dtype_ = np.dtype(dtype)\n",
    "    x, y = np.array(x, dtype=dtype_), np.array(y, dtype=dtype_)\n",
    "    n_obs = x.shape[0]\n",
    "    xy = np.c_[x.reshape(n_obs, -1), y.reshape(n_obs, 1)]\n",
    "    seed = None if random_state is None else int(random_state)\n",
    "    rng = np.random.default_rng(seed=seed)\n",
    "    vector = np.array(start, dtype=dtype_)\n",
    "    learn_rate = np.array(learn_rate, dtype=dtype_)\n",
    "    # Setting up the decay rate\n",
    "    decay_rate = np.array(decay_rate, dtype=dtype_)\n",
    "    batch_size = int(batch_size)\n",
    "    n_iter = int(n_iter)\n",
    "    tolerance = np.array(tolerance, dtype=dtype_)\n",
    "    # Setting the difference to zero for the first iteration\n",
    "    diff = 0\n",
    "    iteration_counter = 0\n",
    "    iteration_5thousand = 0\n",
    "    for _ in range(n_iter):\n",
    "        rng.shuffle(xy)\n",
    "        for start in range(0, n_obs, batch_size):\n",
    "            stop = start + batch_size\n",
    "            x_batch, y_batch = xy[start:stop, :-1], xy[start:stop, -1:]\n",
    "            # Recalculating the difference\n",
    "            grad = np.array(gradient(x_batch, y_batch, vector), dtype_)\n",
    "            diff = decay_rate * diff - learn_rate * grad\n",
    "            vector += diff\n",
    "        if iteration_counter == 5000:\n",
    "            iteration_5thousand += 5000\n",
    "            iteration_counter = 0\n",
    "            print(f'vector is {vector}, iteration {iteration_5thousand}')\n",
    "        iteration_counter += 1\n",
    "    return vector if vector.shape else vector.item()\n",
    "# Apply to the previous quadratic result\n",
    "x = np.array([1,3,5,7,9])\n",
    "y = np.array(x**2 + 4 * x + 7)\n",
    "def returned_gradient(x, y, b): \n",
    "    res = b[0] * x ** 2 + b[1] * x + b[2] - y\n",
    "    return (res * x ** 2).mean(), (res * x).mean(), res.mean()\n",
    "sgd_d(returned_gradient, x, y, start=[1,1,1],\n",
    "learn_rate=0.0005, n_iter=50001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Important observation about convergence / divergence\n",
    "Now I want to experiment. In SGD with no momentum we got very close to optimum (by this I mean when the last parameter exceeds 6.99 since it is the slowest out of those 3 to converge) within 30 000 iteration. Now let's set decay_rate to be 0.2; the same result is got within 27 000 iteration. Now set decay_rate to be 0.5. As a result, our values diverge. Within $\\alpha = 0.3$ we converged already on 19 000 iteration. As we see, the method works. However, it is vital not to set the parameter being too big. It will result in the divergence of the estimated parameters (the same problem as with learning rate). Note that we can get similar but not exactly same results due to randomness and the absence of random state which can ensure us having same results. However, I still do not see any point in it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 What else can we do?\n",
    "\n",
    "The main problem of GD in its various terms is the learning rate. If we set it to be too big - we diverge; if we set it to be too small - we either will be stuck near some point and will not converge or we will converge but not in the optimal way (as the same things could have been done much faster). What I did before is just experimenting with different values, setting them to be constant throughout the entire fulfillment of the algorithm and after that choosing those I have considered to be suitable for both avoiding the divergence and getting relatively fast convergence. However, this is not the best way to do it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 The better approach is rescaling the learning rate at each iteration\n",
    "\n",
    "###### There are two heuristics:\n",
    "\n",
    "1) when cost function value decreases after an iteration, the step could have been larger. That is why, we try to increase it\n",
    "\n",
    "2) when cost function value increases after a step, the step-size was too large. That is why we need to undo the step with the descreased learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8 How do we change the step-size?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some basic strategies to adjust learning rate over time (piecewise constant, exponential decay, polynomial decay) as well as more complex ones. The idea of complex methods is that now learning rate becomes a time dependent decreasing function. The further we go, the closere we get to the optimum and the more careful we need to be since in case we skip the optimum our loss function will start to increase and go to infinity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.9 RMSprop\n",
    "\n",
    "We will not talk about AdaGrad and move straight to its imrpoved version. Starting from now, I will not explain the way algorithms can be coded - in my article this section is an Appendix one \n",
    "\n",
    "###### The basic formula remains the same\n",
    "\n",
    "### $x^{(t+1)} = x^{(t)} - \\eta \\nabla f(x^{(t)})$.\n",
    "\n",
    "###### However, now the learning rate is not a constant, it is a function:\n",
    "\n",
    "### $\\eta_t = \\frac{\\eta_0}{\\sqrt{w_{avg} + \\epsilon}}$,\n",
    "\n",
    "where \n",
    "\n",
    "### $w_{avg_t} = \\zeta w_{avg_{t-1}} + (1-\\zeta) (\\nabla f(x^{(t)}))^2$.\n",
    "\n",
    "$w_{avg_t}$ stands for the weighted average at time t. The parameter $\\zeta$ represents for how much at a particular step we need to take into consideration the previous step and for how much do we need to take into consideration the newly calculated gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.10 Adam as a combination of RMSprop and Momentum\n",
    "\n",
    "Probably one of the best modifications of the SGD algorithm and very widely used technique in Deep Learning for training neural networks is the Adam method. Despite it is usually interpreted as a rather complicated and advanced one, it will not be challenging for us since we are already familiar with everything needed to study it. Remember two important formulas: \n",
    "\n",
    "### 1) $x^{(t+1)} := x^{(t)} - \\eta * v_{dx^{(t+1)}}$,\n",
    "\n",
    "where \n",
    "\n",
    "### $v_{dx^{(t+1)}} = \\gamma * v_{t} + (1- \\gamma) * \\nabla f_i(x^{(t)})$ \n",
    "\n",
    "### 2) $x^{(t+1)} := x^{(t)} - \\frac{\\eta * \\nabla f_i(x^{(t+1)})}{\\sqrt{w_{avg_t} + \\epsilon}}$, \n",
    "\n",
    "where \n",
    "\n",
    "### $w_{avg_t} = \\zeta w_{avg_{t-1}} + (1-\\zeta) (\\nabla f_i(x^{(t)}))^2$ \n",
    "\n",
    "The first one is the representation of the momentum method, while the second one stands for the RMSprop optimizer. Now the only thing left is coming up with a formula combining this two elements. Here it is:\n",
    "\n",
    "### $x^{(t+1)} := x^{(t)} - \\eta * \\frac{v_{dx^{(t+1)}}}{\\sqrt{w_{avg_{t+1}}+ \\epsilon}}.$\n",
    "\n",
    "\n",
    "###### This is the Adam method. The inventors of the algorithm in their book recommend using $\\gamma = 0.9$ and $\\zeta = 0.999$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Conclusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, we started with the introduction to types of problems which include convex optimization. After that, we gave a brief talk about how these problems can be solved and moved to iterative methods. Then, it turned out that gradient descent algorithm is one of the best and universal solutions for the convex optimization problems. Despite all its advantages, the simplest form had many drawbacks we discussed. That is why we moved to the most important part of the research - mathematical and intuitive explanation and programming of several methods which help to overcome mentioned issues. Finally, we understood how to combine all of them (SGD, Momentum, Adaptive Learning Rate) in one tool - Adam, which is found one of the most widely used and powerful nowadays. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 What else I have done while studying machine learning?\n",
    "\n",
    "The GD and SGD algorithms in their variations were the key ML topics for a long time since they were related to the university project and those topics we discussed and studied with my scientific director. However, I am interested in the other parts of ML as well as DL too (I believe that in the future neural networks will play an even more important role in our lives, so it is necessary to understand the way they are used), that is why I do study maths and codes of other algorithms. Despite that I am not doing it for a long time, by today I have already had experience with digits recognition with the help of logistic regression, iris classification using SVM (linear kernel) and clusterization of Kinopoisk TV-series using K-means, Hierarhical and Louvain algorithms (it was done as a home-work mini-project). What is more, I am familiar with basic concepts and terminology, such as overfitting, regularization, accuracy, ROC and AUC and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 What are the plans for the future?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Continue working on the project. I want to move to the applied part, since SGD is commonly used in Deep Learning, which I am interested in\n",
    "\n",
    "2) Continue studying advanced Machine Learning algorithms (both mathematics of them and coding)\n",
    "\n",
    "3) Use GD and SGD while implementing other algorithms (since most of the time the ultimate problem is to minimize a certain convex function and here what I am currently studying is the key helper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 7 References\n",
    " 1) https://d2l.ai/chapter_optimization/sgd.html (unbiased estimate and information about the update of the learning rate)\n",
    " \n",
    " 2) https://realpython.com/gradient-descent-algorithm-python/ (how to code GD and SGD & some basic ideas about it)\n",
    " \n",
    " 3) codebasics (probably one of the best Youtube channels to start learning ML in Python)\n",
    " \n",
    " 4) StatQuest (Youtube channel where one can find intuitive explanations of ML algorithms)\n",
    " \n",
    " 5) stanfordonline, CS229 (A course which gives comprehensive view over ML algorithms)\n",
    " \n",
    " 6) Mathematics for Machine Learning (a book which allows to master all the necessary prerequisites for studying machine learning)\n",
    " \n",
    " 7) DeepLearningAI courses (the explanation of RMSprop and Adam methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thank you for the attention!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
